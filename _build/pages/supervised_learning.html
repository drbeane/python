---
redirect_from:
  - "/pages/supervised-learning"
interact_link: content/pages/supervised_learning.ipynb
kernel_name: python3
has_widgets: false
title: |-
  Supervised Learning
pagenum: 65
prev_page:
  url: /pages/foo5.html
next_page:
  url: /pages/linear_regression.html
suffix: .ipynb
search: model data training models set validation accuracy scikit learn learning well observations not sets iris three performance algorithm dataset create our decision classification flower sample split supervised into logistic tree k predictions new testing test predict example package creating used species called regression class might very its calculate achieved algorithms machine different us nearest neighbors building should using train method x observation tools working contains sepal length width petal consider particular array cell want perform generate created being mymodel based knn score lesson introduction mentioned goal task produce label values provide provides import load numpy several dataframe newly observed while

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Supervised Learning</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Lesson-22---Introduction-to-Classification">Lesson 22 - Introduction to Classification<a class="anchor-link" href="#Lesson-22---Introduction-to-Classification"> </a></h1><h3 id="The-following-topics-are-discussed-in-this-notebook:">The following topics are discussed in this notebook:<a class="anchor-link" href="#The-following-topics-are-discussed-in-this-notebook:"> </a></h3><ul>
<li>Overview of the supervised learning workflow. </li>
<li>Introduction to the Scikit-Learn API. </li>
<li>Training, validation, and test sets. </li>
<li>Classification algorithms</li>
<li>Accuracy as a metric for classification tasks. </li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction-to-Classification">Introduction to Classification<a class="anchor-link" href="#Introduction-to-Classification"> </a></h2><p>As mentioned in the previous lesson, the goal in a supervised learning task is to produce a <strong>model</strong> that we can use to predict the value of a label $y$ given values for a set of features, $x^{(1)}, x^{(2)}, ..., x^{(n)}$. In a classification problem, the label represents a category into which the observation has been classified.</p>
<p>In this lesson, we will provide a general overview of the workflow in supervised learning by walking through an example of a classification task. We will simplify some of the steps in this introductory example, and will not explain all of the details.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Scikit-Learn">Scikit-Learn<a class="anchor-link" href="#Scikit-Learn"> </a></h2><p>The most popular Python library for machine learning is the Scikit-Learn (<code>sklearn</code>) package. This package provides functions for creating supervised learning models, as well as for performing unsupervised learning tasks. Scikit-Learn also provides tools for working with and preparing data for use in creating models.</p>
<p>The tools provided by Scikit-Learn are arranged into various modules. We will typically not import the entire package, but will instead import the required tools as needed.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Load-Packages">Load Packages<a class="anchor-link" href="#Load-Packages"> </a></h2><p>We will begin by loading three packages: Numpy, Pandas, and Matplotlib.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>               
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>              
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>  
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Iris-Dataset">Iris Dataset<a class="anchor-link" href="#Iris-Dataset"> </a></h2><p>For this example, we will be working with the Iris Dataset. This data set is a real-world "toy" dataset that is often used to demonstrate concepts in data science. The iris dataset contains information about several flowers selected from three different species of iris: versicolor, setosa, and virginica.</p>
<p>For each flower, we have five pieces of information:</p>
<ul>
<li>The sepal length of the flower. </li>
<li>The sepal width of the flower. </li>
<li>The petal length of the flower.</li>
<li>The petal width of the flower. </li>
<li>The species of the flower. </li>
</ul>
<p>The original iris dataset contains 150 observations. We will be working with a modified version of this dataset that contains 600 observations. The extra 450 observations were randomly generated to be similar to existing observations.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://drbeane.github.io/files/images/303/Iris.png" alt="Iris"></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Load-and-Explore-Data">Load and Explore Data<a class="anchor-link" href="#Load-and-Explore-Data"> </a></h2><p>The data is stored in the tab-separated file <code>data/iris_mod.txt</code>. We will use Pandas to load the data into a DataFrame called <code>iris</code>. We will then look at the first 10 observations in the DataFrame.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/iris_mod.txt&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">iris</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal_length</th>
      <th>sepal_width</th>
      <th>petal_length</th>
      <th>petal_width</th>
      <th>species</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6.3</td>
      <td>3.2</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>virginica</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.3</td>
      <td>3.8</td>
      <td>1.9</td>
      <td>0.4</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.5</td>
      <td>2.9</td>
      <td>5.8</td>
      <td>1.5</td>
      <td>virginica</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6.5</td>
      <td>3.0</td>
      <td>4.8</td>
      <td>1.6</td>
      <td>versicolor</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6.8</td>
      <td>3.1</td>
      <td>4.9</td>
      <td>1.5</td>
      <td>versicolor</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6.1</td>
      <td>2.3</td>
      <td>4.4</td>
      <td>1.3</td>
      <td>versicolor</td>
    </tr>
    <tr>
      <th>6</th>
      <td>4.9</td>
      <td>3.5</td>
      <td>1.6</td>
      <td>0.4</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>7</th>
      <td>6.3</td>
      <td>3.1</td>
      <td>5.7</td>
      <td>1.7</td>
      <td>virginica</td>
    </tr>
    <tr>
      <th>8</th>
      <td>4.9</td>
      <td>3.5</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>setosa</td>
    </tr>
    <tr>
      <th>9</th>
      <td>5.5</td>
      <td>3.9</td>
      <td>1.3</td>
      <td>0.4</td>
      <td>setosa</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can use the Seaborn package to create a pairs plot of the the dataset.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">iris</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;species&quot;</span><span class="p">,</span> <span class="n">plot_kws</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../images/pages/supervised_learning_10_0.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Goal">The Goal<a class="anchor-link" href="#The-Goal"> </a></h2><p>Our goal is to build a model that will allow us to predict the species of a newly observed flower for which we have measurements for sepal length, sepal width, petal length, and petal width.</p>
<p>We will consider three different models: a logistic regression model, and a decision tree model, and a K-nearest neighbors model. We will use the package Scikit-Learn to construct, assess, and apply both of these models.</p>
<p>Scikit-Learn is a library that contains implementations of many machine learning algorithms, as well as useful tools for evaluatting models, processing data, and generating synthetic data sets. We will use this package extensively in this class.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Prepare-the-Data">Prepare the Data<a class="anchor-link" href="#Prepare-the-Data"> </a></h2><p>The Scikit-Learn model-building API requires our data to be in a specific format. In particular, the features should be represented numerically, and contained in a DataFrame or 2D Numpy Array, while the labels should be contained in a list, series, or 1D Numpy array.</p>
<p>In the next cell, we create a feature array called <code>X</code>, as well as a label array called <code>y</code>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of X:&quot;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of y:&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class &#39;numpy.ndarray&#39;&gt;
&lt;class &#39;numpy.ndarray&#39;&gt;
Shape of X: (600, 4)
Shape of y: (600,)
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Splitting-the-Data-into-Training,-Validation,-and-Test-Sets">Splitting the Data into Training, Validation, and Test Sets<a class="anchor-link" href="#Splitting-the-Data-into-Training,-Validation,-and-Test-Sets"> </a></h2><p>When creating a supervised learning model, it is important to evaluate the model's performance. For a classification model, for example, we might want to measure the model's <strong>accuracy</strong>, or in other words, the proportion of observations for which it makes correct predictions.</p>
<p>Some supervised learning models are very good at "remembering" the data on which they are trained. Such a model might perform very well when evaluated on this data, while performing very poorly on new data that it did not see during training. This phenomenon is called <strong>overfitting</strong>. An overfit model performs unreasonably well on the training data, but will not generalize well to new observations.</p>
<p>For this reason, it is important to evaluate your model using <strong>out-of-sample data</strong>, or in other words, using data that your model did not see during training. One of the most straight-forward methods for estimating a model's out-of-sample performance is to split the data into three sets: the <strong>training set</strong>, the <strong>validation set</strong>, and the <strong>testing set</strong>. The purpose of each of these sets are described below:</p>
<ul>
<li><p>The <strong>training set</strong> is used to train any models that we create. We will provide the training set to a machine learning algorithm as input, and the algorithm will generate a model as its output.</p>
</li>
<li><p>The <strong>validation set</strong> is out-of-sample data used to compare the models we have created. We will often wish to consider multiple different learning algorithms in a supervised learning task. Each algorithm will produce a single model that has been trained on the training set, and we will then compare the performance of the resulting models on the (previously unseen) validation set to help us select our final model.</p>
</li>
<li><p>The <strong>testing set</strong> is out-of-sample data that is used to assess the performance of our final model. This set is used only once, at the very end of the model building process.</p>
</li>
</ul>
<h2 id="Size-of-Training,-Validation,-and-Test-Sets">Size of Training, Validation, and Test Sets<a class="anchor-link" href="#Size-of-Training,-Validation,-and-Test-Sets"> </a></h2><p>There is no set rule for how many observations should go into each of these sets, but there are two guiding principles to follow: You want to include as many observations as possible in the training set, but you don't want the validation or testing sets to be too small to give you reasonable estimates of the out-of-sample performance. If the data set is fairly large, you might use 80% of it for training, 10% for validation, and 10% for testing. This is referred to as an 80/10/10 split. In a small dataset, an 80/10/10 split might create validation and testing sets that are too small. In these cases, you might consider a 60/20/20 split, or a 40/30/30 split.</p>
<h2 id="Using-Scikit-Learn-to-Split-Data">Using Scikit-Learn to Split Data<a class="anchor-link" href="#Using-Scikit-Learn-to-Split-Data"> </a></h2><p>When splitting your data into training, validation, and testing sets, it is import to first randomly shuffle the observations in your data. We could do this manually, but fortunately, Scikit-Learn provides a function called <code>train_test_split</code> for creating a train/test/validation split. We use this function in the cell below to perform an 80/10/10 split on our data.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_hold</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_hold</span> <span class="o">=</span>\
    <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.20</span><span class="p">,</span>
                     <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="n">X_valid</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span>\
    <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_hold</span><span class="p">,</span> <span class="n">y_hold</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.50</span><span class="p">,</span>
                     <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_hold</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">train_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">valid_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">test_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training features shape:  &#39;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation features shape:&#39;</span><span class="p">,</span> <span class="n">X_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test features shape:      &#39;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training labels shape:    &#39;</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation labels shape:  &#39;</span><span class="p">,</span> <span class="n">y_valid</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test labels shape:        &#39;</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training label dist:      &#39;</span><span class="p">,</span> <span class="n">train_dist</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation label dist:    &#39;</span><span class="p">,</span> <span class="n">valid_dist</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test label dist:          &#39;</span><span class="p">,</span> <span class="n">test_dist</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training features shape:   (480, 4)
Validation features shape: (60, 4)
Test features shape:       (60, 4)

Training labels shape:     (480,)
Validation labels shape:   (60,)
Test labels shape:         (60,)

Training label dist:       [160 160 160]
Validation label dist:     [20 20 20]
Test label dist:           [20 20 20]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We mentioned that the training/validation/test set approach is the most straight-forward method of estimating a model's out-of-sample performance. More sophisticated methods exist. In particular, there is a more advanced method called <strong>K-Fold Cross-Validation</strong> that will produce better estimates of a model's performance, at the cost of being more computationally expensive. This is somewhat advanced topic that we are not ready to formally introduce at this point.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Creating-Models-in-Scikit-Learn">Creating Models in Scikit-Learn<a class="anchor-link" href="#Creating-Models-in-Scikit-Learn"> </a></h2><p>Scikit-Learn includes implementations for several machine learning algorithms. All models in Scikit-Learn are created and applied with a similar syntax, regardless of the type of the model.</p>
<p>To build a machine learning model in Scikit-Learn, you must first select a specific model type, or model algorithm that we wish to use. This will determine the general structure of the model being built, but not any of the details about how it will generate its predictions.</p>
<p>Each algorithm will have a special class associated with it. Assume that <code>ModelType</code> is such a class. We start the modeling process by creating an instance of this class. Some algorithms require us to specify certain model options, or <strong>hyperparameters</strong> at this step.</p>

<pre><code>my_model = ModelType(arg1, arg2, ...)

</code></pre>
<p>You should think of <code>my_model</code> as being a blank model at this point. It has not yet seen our dataset, and has not yet learned how to generate predictions. Every <code>sklearn</code> model comes with a <code>fit()</code> method that we can use train it.</p>

<pre><code>my_model.fit(X_train, y_train)

</code></pre>
<p>That's it! We now have a working model. If we want to use the model to generate predictions based on a particular set of feature values, we can use the model's <code>predict()</code> method.</p>

<pre><code>predictions = my_model.predict(X_values)</code></pre>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-Building:-Logistic-Regression">Model Building: Logistic Regression<a class="anchor-link" href="#Model-Building:-Logistic-Regression"> </a></h2><p>Logistic regression is a classification algorithm that is designed to create linear boundaries between the different classes. In the next cell, we will use Scikit-Learn to create and train (or fit) a logistic regression model. We will then use the model to predict the species of a newly observed iris.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># Creating Model</span>
<span class="n">model_1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)</span>
<span class="n">model_1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Create new observation</span>
<span class="n">x0</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">4</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]]</span>

<span class="c1"># Generate prediction</span>
<span class="n">pred_0_m1</span> <span class="o">=</span> <span class="n">model_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pred_0_m1</span><span class="p">)</span>

<span class="c1"># Predicted probabilities</span>
<span class="n">prob_0_m1</span> <span class="o">=</span> <span class="n">model_1</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">prob_0_m1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;setosa&#39;]
[[0.6021 0.3979 0.    ]]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-Building:-Decision-Trees">Model Building: Decision Trees<a class="anchor-link" href="#Model-Building:-Decision-Trees"> </a></h2><p>A decision tree algorithm employs a "divide and conquer" strategy to create a rules-based model for making classifications. We now use Scikit-Learn to create and train a decision model. As before, we will use the model to predict the species of a newly observed iris.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Creating Model</span>
<span class="n">model_2</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">model_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Generate prediction</span>
<span class="n">pred_0_m2</span> <span class="o">=</span> <span class="n">model_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pred_0_m2</span><span class="p">)</span>

<span class="c1"># Predicted probabilities</span>
<span class="n">prob_0_m2</span> <span class="o">=</span> <span class="n">model_2</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">prob_0_m2</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;setosa&#39;]
[[1. 0. 0.]]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-Building:-K-Nearest-Neighbors">Model Building: K-Nearest Neighbors<a class="anchor-link" href="#Model-Building:-K-Nearest-Neighbors"> </a></h2><p>The K-Nearest Neighbors classifier is a distance-based algorithm. Several different KNN models can be created for a particular training set, and these models are distinguished from one another by the choice of a hyperparameter <code>K</code>.</p>
<p>To classify an observation according to this algorithm, you would first find the <code>K</code> training observations that are nearest to the observation being classified. The distance between two observations is based on the differences between their feature values. Once the <code>K</code> nearest neighbors are identified, they are asked to vote on the predicted class for the new observation, with each of the neighbors submitting their own class as the vote.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="c1"># Creating Model</span>
<span class="n">model_3</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">model_3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Generate prediction</span>
<span class="n">pred_0_m3</span> <span class="o">=</span> <span class="n">model_3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pred_0_m3</span><span class="p">)</span>

<span class="c1"># Predicted probabilities</span>
<span class="n">prob_0_m3</span> <span class="o">=</span> <span class="n">model_3</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">prob_0_m3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;setosa&#39;]
[[1. 0. 0.]]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Comparing-Models">Comparing Models<a class="anchor-link" href="#Comparing-Models"> </a></h2><p>For the single iris that we considered above, the three models we created all agreed on the predicted species of the flower. It will not always be the case that models agree in their predictions. Consider the following example.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">obs0</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">obs1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">]</span>
<span class="n">obs2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">obs3</span> <span class="o">=</span> <span class="p">[</span><span class="mf">5.5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">1.8</span><span class="p">]</span>
<span class="n">X_new</span> <span class="o">=</span> <span class="p">[</span><span class="n">obs0</span><span class="p">,</span> <span class="n">obs1</span><span class="p">,</span> <span class="n">obs2</span><span class="p">,</span> <span class="n">obs3</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model 1 Predictions:&#39;</span><span class="p">,</span> <span class="n">model_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model 2 Predictions:&#39;</span><span class="p">,</span> <span class="n">model_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Model 3 Predictions:&#39;</span><span class="p">,</span> <span class="n">model_3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model 1 Predictions: [&#39;versicolor&#39; &#39;virginica&#39; &#39;versicolor&#39; &#39;virginica&#39;]
Model 2 Predictions: [&#39;setosa&#39; &#39;virginica&#39; &#39;setosa&#39; &#39;versicolor&#39;]
Model 3 Predictions: [&#39;versicolor&#39; &#39;virginica&#39; &#39;versicolor&#39; &#39;versicolor&#39;]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can use DataFrames to dispaly these predictions in a more readable format.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span>
    <span class="n">model_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">),</span> 
    <span class="n">model_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">),</span> 
    <span class="n">model_3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;obs0&#39;</span><span class="p">,</span> <span class="s1">&#39;obs1&#39;</span><span class="p">,</span> <span class="s1">&#39;obs2&#39;</span><span class="p">,</span> <span class="s1">&#39;obs3&#39;</span><span class="p">]</span>
<span class="n">predictions</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Model 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Model 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Model 3&#39;</span><span class="p">]</span>
<span class="n">predictions</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>obs0</th>
      <th>obs1</th>
      <th>obs2</th>
      <th>obs3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Model 1</th>
      <td>versicolor</td>
      <td>virginica</td>
      <td>versicolor</td>
      <td>virginica</td>
    </tr>
    <tr>
      <th>Model 2</th>
      <td>setosa</td>
      <td>virginica</td>
      <td>setosa</td>
      <td>versicolor</td>
    </tr>
    <tr>
      <th>Model 3</th>
      <td>versicolor</td>
      <td>virginica</td>
      <td>versicolor</td>
      <td>versicolor</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Scoring-Models-Using-Accuracy">Scoring Models Using Accuracy<a class="anchor-link" href="#Scoring-Models-Using-Accuracy"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The three models above disagree in their prediction for the three of the flowers. So which model should we use?</p>
<p>It would perhaps be instructive to see how well the models actually performed on the training data. To that end, we will calculate each model's <strong>accuracy</strong> on the training set. We will start with <code>model_1</code>, the logistic regression model.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Logistic Regression Model Accuracy</span>

<span class="n">mod1_pred_train</span> <span class="o">=</span> <span class="n">model_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">mod1_train_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mod1_pred_train</span> <span class="o">==</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mod1_train_acc</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.9604166666666667
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will now calculate the training accuracy for the decision tree model, <code>model_2</code>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Decision Tree Model Accuracy</span>

<span class="n">mod2_pred_train</span> <span class="o">=</span> <span class="n">model_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">mod2_train_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mod2_pred_train</span> <span class="o">==</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mod2_train_acc</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>1.0
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, we calculate the training accuracy for the decision tree model, <code>model_3</code>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># KNN Model Accuracy</span>

<span class="n">mod3_pred_train</span> <span class="o">=</span> <span class="n">model_3</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">mod3_train_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mod3_pred_train</span> <span class="o">==</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mod3_train_acc</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.9708333333333333
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The logistic regression achieved 96% accuracy on the training set, the decision tree model achieved 100% training accuracy, and the KNN model achieved 97% training accuracy. That might seem to indicate that the decision tree model is the best of the three. However, as mentioned before, we are more interested in a model's out-of-sample performance than in its performance on the training data. For this reason, we use the validation set to compare models. So, we need to calculate the <strong>validation accuracy</strong> for each of the three models.</p>
<p>We could calculate the validation accuracies in the same way that we calculated the training accuracies above. However, our models actually come equipped with <code>score()</code> methods that will do this work for us. In the cell below, we will use the <code>score()</code> method to calculate training and validation accuracies for all three of our models.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model 1 Training Accuracy:  &quot;</span><span class="p">,</span> <span class="n">model_1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model 1 Validation Accuracy:&quot;</span><span class="p">,</span> <span class="n">model_1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model 2 Training Accuracy:  &quot;</span><span class="p">,</span> <span class="n">model_2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model 2 Validation Accuracy:&quot;</span><span class="p">,</span> <span class="n">model_2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model 3 Training Accuracy:  &quot;</span><span class="p">,</span> <span class="n">model_3</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model 3 Validation Accuracy:&quot;</span><span class="p">,</span> <span class="n">model_3</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model 1 Training Accuracy:   0.9604166666666667
Model 1 Validation Accuracy: 0.95

Model 2 Training Accuracy:   1.0
Model 2 Validation Accuracy: 0.95

Model 3 Training Accuracy:   0.9708333333333333
Model 3 Validation Accuracy: 0.9833333333333333
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's address these results one model at a time.</p>
<p><strong>Model 1</strong>
The logistic regresesion model achieved 95% accuracy on the validation set. That is slightly lower than its training accuracy. That suggests that the model will perform approximately as well on new data as it did on the training data.</p>
<p><strong>Model 2</strong>
The decision tree model also achieved 95% accuracy on the validation set. That is notably lower than then 100% accuracy it got on the training set. This is an example of <strong>overfitting</strong>. The algorithm learned the nuances of the training set very well. Too well, in fact. It creates a model that performs very well on the data it was provided, but does not generalize well to new observations.</p>
<p><strong>Model 3</strong>
The KNN model achieved a 98.3% validation accuracy, which was actually a bit higher than its performance on the training set. While we wouldn't expect a model to have a validation score that is higher than its testing score, that can certain happen as a result of the random sampling used to create the sets. This does not mean that the model is expected to do better on new data than on the training data, but it does suggest that the model will likely perform about as well on new data as on the training data.</p>
<p>Since the KNN model has the highest validation accuracy, we will select it as our final model. We conclude by using the test set to provide us with an estimate of this model's out-of-sample accuracy.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model 3 Test Accuracy:   &quot;</span><span class="p">,</span> <span class="n">model_3</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model 3 Test Accuracy:    0.9833333333333333
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

 


    </main>
    